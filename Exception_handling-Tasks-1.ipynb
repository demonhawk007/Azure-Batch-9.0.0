{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import uuid\n",
    "import sys\n",
    "import time\n",
    "import config\n",
    "from datetime import datetime, timedelta\n",
    "import azure.storage.blob as azureblob\n",
    "import azure.batch.models as batchmodels\n",
    "import azure.batch._batch_service_client as batch\n",
    "import azure.batch.batch_auth as batch_auth\n",
    "import azure.batch.operations as batchops\n",
    "from azure.batch.models import (VirtualMachineConfiguration, CloudServiceConfiguration, ImageReference,\n",
    "                                BatchErrorException, PoolInformation, JobAddParameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_batch_exception(batch_exception):\n",
    "    \"\"\"\n",
    "    Prints the contents of the specified Batch exception.\n",
    "\n",
    "    :param batch_exception:\n",
    "    \"\"\"\n",
    "    print('-------------------------------------------')\n",
    "    print('Exception encountered:')\n",
    "    if batch_exception.error and \\\n",
    "            batch_exception.error.message and \\\n",
    "            batch_exception.error.message.value:\n",
    "        print(batch_exception.error.message.value)\n",
    "        if batch_exception.error.values:\n",
    "            print()\n",
    "            for mesg in batch_exception.error.values:\n",
    "                print('{}:\\t{}'.format(mesg.key, mesg.value))\n",
    "    print('-------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_file_to_container(block_blob_client, container_name, file_path):\n",
    "    \"\"\"\n",
    "    Uploads a local file to an Azure Blob storage container.\n",
    "\n",
    "    :param block_blob_client: A blob service client.\n",
    "    :type block_blob_client: `azure.storage.blob.BlockBlobService`\n",
    "    :param str container_name: The name of the Azure Blob storage container.\n",
    "    :param str file_path: The local path to the file.\n",
    "    :rtype: `azure.batch.models.ResourceFile`\n",
    "    :return: A ResourceFile initialized with a SAS URL appropriate for Batch\n",
    "    tasks.\n",
    "    \"\"\"\n",
    "    blob_name = os.path.basename(file_path)\n",
    "\n",
    "    print('Uploading file {} to container [{}]...'.format(file_path,\n",
    "                                                          container_name))\n",
    "\n",
    "    block_blob_client.create_blob_from_path(container_name,\n",
    "                                            blob_name,\n",
    "                                            file_path)\n",
    "\n",
    "    sas_token = block_blob_client.generate_blob_shared_access_signature(\n",
    "        container_name,\n",
    "        blob_name,\n",
    "        permission=azureblob.BlobPermissions.READ,\n",
    "        expiry=datetime.utcnow() + timedelta(hours=2))\n",
    "\n",
    "    sas_url = block_blob_client.make_blob_url(container_name,\n",
    "                                              blob_name,\n",
    "                                              sas_token=sas_token)\n",
    "\n",
    "    return batchmodels.ResourceFile(http_url=sas_url, file_path=blob_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_container_sas_token(block_blob_client,\n",
    "                            container_name, blob_permissions):\n",
    "    \"\"\"\n",
    "    Obtains a shared access signature granting the specified permissions to the\n",
    "    container.\n",
    "\n",
    "    :param block_blob_client: A blob service client.\n",
    "    :type block_blob_client: `azure.storage.blob.BlockBlobService`\n",
    "    :param str container_name: The name of the Azure Blob storage container.\n",
    "    :param BlobPermissions blob_permissions:\n",
    "    :rtype: str\n",
    "    :return: A SAS token granting the specified permissions to the container.\n",
    "    \"\"\"\n",
    "    # Obtain the SAS token for the container, setting the expiry time and\n",
    "    # permissions. In this case, no start time is specified, so the shared\n",
    "    # access signature becomes valid immediately.\n",
    "    container_sas_token = \\\n",
    "        block_blob_client.generate_container_shared_access_signature(\n",
    "            container_name,\n",
    "            permission=blob_permissions,\n",
    "            expiry=datetime.utcnow() + timedelta(hours=2))\n",
    "\n",
    "    return container_sas_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _read_stream_as_string(stream, encoding):\n",
    "    \"\"\"Read stream as string\n",
    "    :param stream: input stream generator\n",
    "    :param str encoding: The encoding of the file. The default is utf-8.\n",
    "    :return: The file content.\n",
    "    :rtype: str\n",
    "    \"\"\"\n",
    "    output = io.BytesIO()\n",
    "    try:\n",
    "        for data in stream:\n",
    "            output.write(data)\n",
    "        if encoding is None:\n",
    "            encoding = 'utf-8'\n",
    "        return output.getvalue().decode(encoding)\n",
    "    finally:\n",
    "        output.close()\n",
    "    raise RuntimeError('could not write data to stream or decode bytes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Batch Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "credentials = batch_auth.SharedKeyCredentials(account_name=config._BATCH_ACCOUNT_NAME,key=config._BATCH_ACCOUNT_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_client = batch.BatchServiceClient(credentials=credentials, batch_url=config._BATCH_ACCOUNT_URL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Status of Tasks for the Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_client = batch_client.job.get(job_id = config._JOB_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'PythonQuickstartJob',\n",
       " 'uses_task_dependencies': False,\n",
       " 'url': 'https://azuremgmtbat.eastus.batch.azure.com/jobs/PythonQuickstartJob',\n",
       " 'e_tag': '0x8D83A9E04350766',\n",
       " 'last_modified': '2020-08-07T06:49:22.275312Z',\n",
       " 'creation_time': '2020-08-07T06:49:22.213295Z',\n",
       " 'state': 'active',\n",
       " 'state_transition_time': '2020-08-07T06:49:22.275312Z',\n",
       " 'priority': 0,\n",
       " 'constraints': {'max_wall_clock_time': 'P10675199DT2H48M5.477581S',\n",
       "  'max_task_retry_count': 0},\n",
       " 'pool_info': {'pool_id': 'PythonQuickstartPool'},\n",
       " 'on_all_tasks_complete': 'noaction',\n",
       " 'on_task_failure': 'noaction',\n",
       " 'execution_info': {'start_time': '2020-08-07T06:49:22.275312Z',\n",
       "  'pool_id': 'PythonQuickstartPool'}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_client.as_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate an autoscale formula for the Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "formula = '''startingNumberOfVMs = 0;\n",
    "maxNumberofVMs = 10;\n",
    "pendingTaskSamplePercent = $PendingTasks.GetSamplePercent(180 * TimeInterval_Second);\n",
    "pendingTaskSamples = pendingTaskSamplePercent < 70 ? startingNumberOfVMs : avg($PendingTasks.GetSample(180 * TimeInterval_Second));\n",
    "$TargetLowPriorityNodes=min(maxNumberofVMs, pendingTaskSamples);\n",
    "$NodeDeallocationOption = taskcompletion;'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pool_eval = batch_client.pool.evaluate_auto_scale(pool_id=config._POOL_ID,auto_scale_formula=formula) # To work upon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pool_eval = pool_eval.as_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting to list\n",
    "# pp = pool_eval['results'].replace('$','').replace('=',\";\").split(';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting to Dictionary\n",
    "# pool_stat = dict(zip(pp[::2],pp[1::2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Need to have a check here as well that pendingTaskSamples must be 0 only then we can go ahead\n",
    "while True:\n",
    "    pool_eval = batch_client.pool.evaluate_auto_scale(pool_id=config._POOL_ID,auto_scale_formula=formula) # To work upon\n",
    "    pool_eval = pool_eval.as_dict()\n",
    "    pp = pool_eval['results'].replace('$','').replace('=',\";\").split(';')\n",
    "    pool_stat = dict(zip(pp[::2],pp[1::2]))\n",
    "    if pool_stat['pendingTaskSamples']=='0':    # Need to add Allocation state condition as well\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a Container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the blob client, for use in obtaining references to\n",
    "    # blob storage containers and uploading files to containers.\n",
    "\n",
    "blob_client = azureblob.BlockBlobService(\n",
    "    account_name=config._STORAGE_ACCOUNT_NAME,\n",
    "    account_key=config._STORAGE_ACCOUNT_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the blob client to create the containers in Azure Storage if they\n",
    "    # don't yet exist.\n",
    "\n",
    "input_container_name = 'input'\n",
    "blob_client.create_container(input_container_name, fail_on_exist=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file_paths = [os.path.join(sys.path[0], 'sleep.py'),\n",
    "                    os.path.join(sys.path[0], 'taskdata1.txt'),\n",
    "                    os.path.join(sys.path[0], 'taskdata2.txt'),\n",
    "                    os.path.join(sys.path[0],'commands.bat')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading file /home/fission/Desktop/Azure_batch/Practice/sleep.py to container [input]...\n",
      "Uploading file /home/fission/Desktop/Azure_batch/Practice/taskdata1.txt to container [input]...\n",
      "Uploading file /home/fission/Desktop/Azure_batch/Practice/taskdata2.txt to container [input]...\n",
      "Uploading file /home/fission/Desktop/Azure_batch/Practice/commands.bat to container [input]...\n"
     ]
    }
   ],
   "source": [
    "# Upload the data files.\n",
    "input_files = [\n",
    "    upload_file_to_container(blob_client, input_container_name, file_path)\n",
    "    for file_path in input_file_paths]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = batch_client.pool.enable_auto_scale(pool_id=config._POOL_ID,auto_scale_formula=formula,\n",
    "                                           auto_scale_evaluation_interval=timedelta(minutes=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<azure.batch.models._models_py3.TaskAddCollectionResult at 0x7fa3940f0070>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tasks = list()\n",
    "\n",
    "for idx, input_file in enumerate(input_files):\n",
    "    command = \"/bin/bash -c \\\"python {}\\\"\".format(input_file.file_path)\n",
    "    tasks.append(batch.models.TaskAddParameter(\n",
    "        id='Task{}'.format(idx),\n",
    "        command_line=command,\n",
    "        resource_files=[input_file]\n",
    "    ))\n",
    "batch_client.task.add_collection(config._JOB_ID, tasks) #Adding tasks to the Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Retrieving informating for each task\n",
    "task_id = []\n",
    "boolean = []\n",
    "for i in range(len(tasks)):\n",
    "    id_ = list(batch_client.task.list(job_id=config._JOB_ID))[i].as_dict()\n",
    "    boolean.append(False)\n",
    "    task_id.append(id_['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[False, False, False, False]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boolean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-08-10 01:01:20\n",
      "elapsed time : 0:08:54\n"
     ]
    }
   ],
   "source": [
    "# We may need to need check the status of pool autoscale before going to the next line. Until the Nodes\n",
    "# are allocated, we cant go check the status of Task\n",
    "starttime = datetime.now().replace(microsecond=0)\n",
    "print(starttime)\n",
    "while True:\n",
    "    pool_stat = batch_client.pool.get(pool_id=config._POOL_ID)\n",
    "    pool_stat = pool_stat.as_dict()\n",
    "    if pool_stat['current_low_priority_nodes'] > 0:\n",
    "#         time.sleep(30)    # Node is not ready\n",
    "        break\n",
    "print(f'elapsed time : {datetime.now().replace(microsecond=0)-starttime}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...\n",
      "Monitoring all tasks for 'Completed' state, timeout in 0:30:00......\n",
      "Monitoring all tasks for 'Completed' state, timeout in 0:30:00......\n",
      "Monitoring all tasks for 'Completed' state, timeout in 0:30:00......\n",
      "Monitoring all tasks for 'Completed' state, timeout in 0:30:00......\n",
      "Monitoring all tasks for 'Completed' state, timeout in 0:30:00......\n",
      "Monitoring all tasks for 'Completed' state, timeout in 0:30:00......\n",
      "Monitoring all tasks for 'Completed' state, timeout in 0:30:00......\n",
      "Monitoring all tasks for 'Completed' state, timeout in 0:30:00......\n",
      "Monitoring all tasks for 'Completed' state, timeout in 0:30:00......\n",
      "Monitoring all tasks for 'Completed' state, timeout in 0:30:00......\n",
      "Monitoring all tasks for 'Completed' state, timeout in 0:30:00......\n",
      "Monitoring all tasks for 'Completed' state, timeout in 0:30:00......\n",
      "Monitoring all tasks for 'Completed' state, timeout in 0:30:00......\n",
      "Monitoring all tasks for 'Completed' state, timeout in 0:30:00......\n",
      "Monitoring all tasks for 'Completed' state, timeout in 0:30:00......\n",
      "Monitoring all tasks for 'Completed' state, timeout in 0:30:00......\n",
      "Monitoring all tasks for 'Completed' state, timeout in 0:30:00......\n",
      "Monitoring all tasks for 'Completed' state, timeout in 0:30:00......\n",
      "Monitoring all tasks for 'Completed' state, timeout in 0:30:00......\n",
      "Monitoring all tasks for 'Completed' state, timeout in 0:30:00......\n",
      "Monitoring all tasks for 'Completed' state, timeout in 0:30:00......\n",
      "Monitoring all tasks for 'Completed' state, timeout in 0:30:00......\n",
      "Monitoring all tasks for 'Completed' state, timeout in 0:30:00......\n",
      "Monitoring all tasks for 'Completed' state, timeout in 0:30:00......\n",
      "Monitoring all tasks for 'Completed' state, timeout in 0:30:00......\n",
      "Monitoring all tasks for 'Completed' state, timeout in 0:30:00......\n",
      "Monitoring all tasks for 'Completed' state, timeout in 0:30:00......\n",
      "Monitoring all tasks for 'Completed' state, timeout in 0:30:00......\n",
      "Monitoring all tasks for 'Completed' state, timeout in 0:30:00......\n",
      "Monitoring all tasks for 'Completed' state, timeout in 0:30:00......\n",
      "Monitoring all tasks for 'Completed' state, timeout in 0:30:00......\n",
      "Monitoring all tasks for 'Completed' state, timeout in 0:30:00......\n",
      "Monitoring all tasks for 'Completed' state, timeout in 0:30:00......\n",
      "Monitoring all tasks for 'Completed' state, timeout in 0:30:00......\n",
      "Monitoring all tasks for 'Completed' state, timeout in 0:30:00......\n",
      "Monitoring all tasks for 'Completed' state, timeout in 0:30:00......\n",
      "Monitoring all tasks for 'Completed' state, timeout in 0:30:00......\n",
      "Monitoring all tasks for 'Completed' state, timeout in 0:30:00......\n",
      "Monitoring all tasks for 'Completed' state, timeout in 0:30:00......\n",
      "Monitoring all tasks for 'Completed' state, timeout in 0:30:00......\n",
      "Monitoring all tasks for 'Completed' state, timeout in 0:30:00......\n",
      "Monitoring all tasks for 'Completed' state, timeout in 0:30:00......\n",
      "Monitoring all tasks for 'Completed' state, timeout in 0:30:00......\n",
      "Monitoring all tasks for 'Completed' state, timeout in 0:30:00......\n",
      "Monitoring all tasks for 'Completed' state, timeout in 0:30:00......\n",
      "Monitoring all tasks for 'Completed' state, timeout in 0:30:00......\n",
      "Monitoring all tasks for 'Completed' state, timeout in 0:30:00......\n",
      "Monitoring all tasks for 'Completed' state, timeout in 0:30:00......\n",
      "Monitoring all tasks for 'Completed' state, timeout in 0:30:00......\n",
      "Monitoring all tasks for 'Completed' state, timeout in 0:30:00......\n",
      "Monitoring all tasks for 'Completed' state, timeout in 0:30:00......\n",
      "Monitoring all tasks for 'Completed' state, timeout in 0:30:00......\n",
      "Monitoring all tasks for 'Completed' state, timeout in 0:30:00......\n",
      "Monitoring all tasks for 'Completed' state, timeout in 0:30:00......\n",
      "Monitoring all tasks for 'Completed' state, timeout in 0:30:00......\n",
      "Monitoring all tasks for 'Completed' state, timeout in 0:30:00......\n",
      "Monitoring all tasks for 'Completed' state, timeout in 0:30:00......\n",
      "Monitoring all tasks for 'Completed' state, timeout in 0:30:00......\n",
      "Monitoring all tasks for 'Completed' state, timeout in 0:30:00......\n",
      "Monitoring all tasks for 'Completed' state, timeout in 0:30:00......\n",
      "Monitoring all tasks for 'Completed' state, timeout in 0:30:00......\n",
      "Monitoring all tasks for 'Completed' state, timeout in 0:30:00......\n",
      "Monitoring all tasks for 'Completed' state, timeout in 0:30:00......\n",
      "Monitoring all tasks for 'Completed' state, timeout in 0:30:00......\n",
      "Monitoring all tasks for 'Completed' state, timeout in 0:30:00......\n",
      "Monitoring all tasks for 'Completed' state, timeout in 0:30:00......\n",
      "Monitoring all tasks for 'Completed' state, timeout in 0:30:00......\n",
      "Monitoring all tasks for 'Completed' state, timeout in 0:30:00......\n",
      "Monitoring all tasks for 'Completed' state, timeout in 0:30:00......\n",
      "Monitoring all tasks for 'Completed' state, timeout in 0:30:00......\n",
      "Node: tvmps_b4b16f9c509413e332eeb135ff2f939f6b4d8619533182610e7e42afdbdd81ad_p\n",
      "task id : Task2 is completed\n",
      "Task: Task2\n",
      "std_output : \n",
      "error_output :   File \"taskdata2.txt\", line 1\n",
      "    Azure Storage offers a set of storage services for all your business needs. Choose from Blob Storage (Object Storage) for unstructured data, File Storage for SMB-based cloud file shares, Table Storage for NoSQL data, Queue Storage to reliably store messages, and Premium Storage for high-performance, low-latency block storage for I/O-intensive workloads running in Azure Virtual Machines.\n",
      "                ^\n",
      "SyntaxError: invalid syntax\n",
      "\n",
      "...\n",
      "Node: tvmps_d6a63f7f4562b0f1d29c5635cc823f1c71de3b3bf0e941d8652908911f49fc3a_p\n",
      "task id : Task3 is completed\n",
      "Task: Task3\n",
      "std_output : \n",
      "error_output :   File \"commands.bat\", line 1\n",
      "    apt update\n",
      "             ^\n",
      "SyntaxError: invalid syntax\n",
      "\n",
      "...\n",
      "Monitoring all tasks for 'Completed' state, timeout in 0:30:00......\n",
      "Node: tvmps_b4b16f9c509413e332eeb135ff2f939f6b4d8619533182610e7e42afdbdd81ad_p\n",
      "task id : Task1 is completed\n",
      "Task: Task1\n",
      "std_output : \n",
      "error_output :   File \"taskdata1.txt\", line 1\n",
      "    Batch processing began with mainframe computers and punch cards. Today it still plays a central role in business, engineering, science, and other pursuits that require running lots of automated tasksâ€”processing bills and payroll, calculating portfolio risk, designing new products, rendering animated films, testing software, searching for energy, predicting the weather, and finding new cures for disease. Previously only a few had access to the computing power for these scenarios. With Azure Batch, that power is available to you when you need it, without any capital investment.\n",
      "                   ^\n",
      "SyntaxError: invalid syntax\n",
      "\n",
      "Running another cycle in 30 secs\n",
      "Running another cycle in 30 secs\n",
      "...\n",
      "Monitoring all tasks for 'Completed' state, timeout in 0:30:00...Running another cycle in 30 secs\n",
      "Running another cycle in 30 secs\n",
      "Running another cycle in 30 secs\n",
      "...\n",
      "Node: tvmps_d6a63f7f4562b0f1d29c5635cc823f1c71de3b3bf0e941d8652908911f49fc3a_p\n",
      "task id : Task0 is completed\n",
      "Task: Task0\n",
      "std_output : \n",
      "error_output : \n",
      "elapsed time : 0:16:36\n"
     ]
    }
   ],
   "source": [
    "iscompleted = False\n",
    "while True:\n",
    "    iscompleted = True\n",
    "    try:\n",
    "        for i in range(len(task_id)):\n",
    "            if boolean[i]==False:\n",
    "                status_client = batch_client.task.get(job_id=config._JOB_ID,task_id=task_id[i])\n",
    "                status = status_client.as_dict()\n",
    "                print('...')\n",
    "                print(\"Monitoring all tasks for 'Completed' state, timeout in {}...\"\n",
    "                          .format(timedelta(minutes=30)), end='')\n",
    "                \n",
    "                if status['state'] != 'completed':    # Checking the status of task for completion\n",
    "#                     print(\"task id : {} is {}\".format(task_id[i],status['state'])) \n",
    "                    iscompleted = False\n",
    "                else:\n",
    "                    node_id = batch_client.task.get(job_id=config._JOB_ID,task_id=task_id[i]).node_info.node_id\n",
    "                    print(\"Node: {}\".format(node_id))\n",
    "                    print(\"task id : {} is {}\".format(task_id[i],status['state']))\n",
    "                    print(\"Task: {}\".format(task_id[i]))\n",
    "                    std_stream = batch_client.file.get_from_task(job_id=config._JOB_ID,task_id=task_id[i],\n",
    "                                                                 file_path=config._STANDARD_OUT_FILE_NAME)\n",
    "                    err_stream = batch_client.file.get_from_task(job_id=config._JOB_ID,task_id=task_id[i],\n",
    "                                                                     file_path=config._STANDARD_ERROR_OUT_FILE_NAME)\n",
    "                    \n",
    "                    std_file_text = _read_stream_as_string(std_stream,None)\n",
    "                    print(f'std_output : {std_file_text}')\n",
    "                    \n",
    "                    std_err_file_text = _read_stream_as_string(err_stream,None) \n",
    "                    print(f'error_output : {std_err_file_text}')\n",
    "                    \n",
    "                    boolean[i]=True\n",
    "            elif iscompleted != True:\n",
    "                print(\"Running another cycle in 30 secs\")\n",
    "                time.sleep(30)\n",
    "    except batchmodels.BatchErrorException as err:\n",
    "        print_batch_exception(err)\n",
    "        raise\n",
    "    if iscompleted:\n",
    "        break\n",
    "print(f'elapsed time : {datetime.now().replace(microsecond=0)-starttime}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "tvmps_d6a63f7f4562b0f1d29c5635cc823f1c71de3b3bf0e941d8652908911f49fc3a_p\n",
      "1\n",
      "tvmps_b4b16f9c509413e332eeb135ff2f939f6b4d8619533182610e7e42afdbdd81ad_p\n",
      "2\n",
      "tvmps_b4b16f9c509413e332eeb135ff2f939f6b4d8619533182610e7e42afdbdd81ad_p\n",
      "3\n",
      "tvmps_d6a63f7f4562b0f1d29c5635cc823f1c71de3b3bf0e941d8652908911f49fc3a_p\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(task_id)):\n",
    "    print(i)\n",
    "    node_id = batch_client.task.get(job_id=config._JOB_ID,task_id=task_id[i]).node_info.node_id\n",
    "    print(node_id)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[True, True]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boolean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# task1 gets completed in 10 sec\n",
    "# task2 is in pending\n",
    "# task3 complete\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_count = batch_client.job.get_task_counts(job_id=config._JOB_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'active': 0, 'running': 0, 'completed': 4, 'succeeded': 1, 'failed': 3}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task_count.as_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deleting the tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in task_id:\n",
    "    batch_client.task.delete(job_id=config._JOB_ID,task_id=i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# error = batchmodels.TaskFailureInformation(category='SyntaxError') # Syntax error is not valid error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batchmodels.TaskConstraints() # Need to work on this. This is useful for timeout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(boolean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_client.task.add()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchmodels.OnAllTasksComplete()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
