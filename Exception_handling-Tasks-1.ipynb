{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import uuid\n",
    "import sys\n",
    "import time\n",
    "import config\n",
    "from datetime import datetime, timedelta\n",
    "import azure.storage.blob as azureblob\n",
    "import azure.batch.models as batchmodels\n",
    "import azure.batch._batch_service_client as batch\n",
    "import azure.batch.batch_auth as batch_auth\n",
    "import azure.batch.operations as batchops\n",
    "from azure.batch.models import (VirtualMachineConfiguration, CloudServiceConfiguration, ImageReference,\n",
    "                                BatchErrorException, PoolInformation, JobAddParameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_batch_exception(batch_exception):\n",
    "    \"\"\"\n",
    "    Prints the contents of the specified Batch exception.\n",
    "\n",
    "    :param batch_exception:\n",
    "    \"\"\"\n",
    "    print('-------------------------------------------')\n",
    "    print('Exception encountered:')\n",
    "    if batch_exception.error and \\\n",
    "            batch_exception.error.message and \\\n",
    "            batch_exception.error.message.value:\n",
    "        print(batch_exception.error.message.value)\n",
    "        if batch_exception.error.values:\n",
    "            print()\n",
    "            for mesg in batch_exception.error.values:\n",
    "                print('{}:\\t{}'.format(mesg.key, mesg.value))\n",
    "    print('-------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_file_to_container(block_blob_client, container_name, file_path):\n",
    "    \"\"\"\n",
    "    Uploads a local file to an Azure Blob storage container.\n",
    "\n",
    "    :param block_blob_client: A blob service client.\n",
    "    :type block_blob_client: `azure.storage.blob.BlockBlobService`\n",
    "    :param str container_name: The name of the Azure Blob storage container.\n",
    "    :param str file_path: The local path to the file.\n",
    "    :rtype: `azure.batch.models.ResourceFile`\n",
    "    :return: A ResourceFile initialized with a SAS URL appropriate for Batch\n",
    "    tasks.\n",
    "    \"\"\"\n",
    "    blob_name = os.path.basename(file_path)\n",
    "\n",
    "    print('Uploading file {} to container [{}]...'.format(file_path,\n",
    "                                                          container_name))\n",
    "\n",
    "    block_blob_client.create_blob_from_path(container_name,\n",
    "                                            blob_name,\n",
    "                                            file_path)\n",
    "\n",
    "    sas_token = block_blob_client.generate_blob_shared_access_signature(\n",
    "        container_name,\n",
    "        blob_name,\n",
    "        permission=azureblob.BlobPermissions.READ,\n",
    "        expiry=datetime.utcnow() + timedelta(hours=2))\n",
    "\n",
    "    sas_url = block_blob_client.make_blob_url(container_name,\n",
    "                                              blob_name,\n",
    "                                              sas_token=sas_token)\n",
    "\n",
    "    return batchmodels.ResourceFile(http_url=sas_url, file_path=blob_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_container_sas_token(block_blob_client,\n",
    "                            container_name, blob_permissions):\n",
    "    \"\"\"\n",
    "    Obtains a shared access signature granting the specified permissions to the\n",
    "    container.\n",
    "\n",
    "    :param block_blob_client: A blob service client.\n",
    "    :type block_blob_client: `azure.storage.blob.BlockBlobService`\n",
    "    :param str container_name: The name of the Azure Blob storage container.\n",
    "    :param BlobPermissions blob_permissions:\n",
    "    :rtype: str\n",
    "    :return: A SAS token granting the specified permissions to the container.\n",
    "    \"\"\"\n",
    "    # Obtain the SAS token for the container, setting the expiry time and\n",
    "    # permissions. In this case, no start time is specified, so the shared\n",
    "    # access signature becomes valid immediately.\n",
    "    container_sas_token = \\\n",
    "        block_blob_client.generate_container_shared_access_signature(\n",
    "            container_name,\n",
    "            permission=blob_permissions,\n",
    "            expiry=datetime.utcnow() + timedelta(hours=2))\n",
    "\n",
    "    return container_sas_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _read_stream_as_string(stream, encoding):\n",
    "    \"\"\"Read stream as string\n",
    "    :param stream: input stream generator\n",
    "    :param str encoding: The encoding of the file. The default is utf-8.\n",
    "    :return: The file content.\n",
    "    :rtype: str\n",
    "    \"\"\"\n",
    "    output = io.BytesIO()\n",
    "    try:\n",
    "        for data in stream:\n",
    "            output.write(data)\n",
    "        if encoding is None:\n",
    "            encoding = 'utf-8'\n",
    "        return output.getvalue().decode(encoding)\n",
    "    finally:\n",
    "        output.close()\n",
    "    raise RuntimeError('could not write data to stream or decode bytes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Batch Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "credentials = batch_auth.SharedKeyCredentials(account_name=config._BATCH_ACCOUNT_NAME,key=config._BATCH_ACCOUNT_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_client = batch.BatchServiceClient(credentials=credentials, batch_url=config._BATCH_ACCOUNT_URL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Status of Tasks for the Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_client = batch_client.job.get(job_id = config._JOB_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'PythonQuickstartJob',\n",
       " 'uses_task_dependencies': False,\n",
       " 'url': 'https://azuremgmtbat.eastus.batch.azure.com/jobs/PythonQuickstartJob',\n",
       " 'e_tag': '0x8D83A9E04350766',\n",
       " 'last_modified': '2020-08-07T06:49:22.275312Z',\n",
       " 'creation_time': '2020-08-07T06:49:22.213295Z',\n",
       " 'state': 'active',\n",
       " 'state_transition_time': '2020-08-07T06:49:22.275312Z',\n",
       " 'priority': 0,\n",
       " 'constraints': {'max_wall_clock_time': 'P10675199DT2H48M5.477581S',\n",
       "  'max_task_retry_count': 0},\n",
       " 'pool_info': {'pool_id': 'PythonQuickstartPool'},\n",
       " 'on_all_tasks_complete': 'noaction',\n",
       " 'on_task_failure': 'noaction',\n",
       " 'execution_info': {'start_time': '2020-08-07T06:49:22.275312Z',\n",
       "  'pool_id': 'PythonQuickstartPool'}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_client.as_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate an autoscale formula for the Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "formula = '''startingNumberOfVMs = 0;\n",
    "maxNumberofVMs = 10;\n",
    "pendingTaskSamplePercent = $PendingTasks.GetSamplePercent(180 * TimeInterval_Second);\n",
    "pendingTaskSamples = pendingTaskSamplePercent < 70 ? startingNumberOfVMs : avg($PendingTasks.GetSample(180 * TimeInterval_Second));\n",
    "$TargetLowPriorityNodes=min(maxNumberofVMs, pendingTaskSamples);\n",
    "$NodeDeallocationOption = taskcompletion;'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pool_eval = batch_client.pool.evaluate_auto_scale(pool_id=config._POOL_ID,auto_scale_formula=formula) # To work upon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pool_eval = pool_eval.as_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting to list\n",
    "# pp = pool_eval['results'].replace('$','').replace('=',\";\").split(';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting to Dictionary\n",
    "# pool_stat = dict(zip(pp[::2],pp[1::2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Need to have a check here as well that pendingTaskSamples must be 0 only then we can go ahead\n",
    "while True:\n",
    "    pool_eval = batch_client.pool.evaluate_auto_scale(pool_id=config._POOL_ID,auto_scale_formula=formula) # To work upon\n",
    "    pool_eval = pool_eval.as_dict()\n",
    "    pp = pool_eval['results'].replace('$','').replace('=',\";\").split(';')\n",
    "    pool_stat = dict(zip(pp[::2],pp[1::2]))\n",
    "    if pool_stat['pendingTaskSamples']=='0':    # Need to add Allocation state condition as well\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a Container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the blob client, for use in obtaining references to\n",
    "    # blob storage containers and uploading files to containers.\n",
    "\n",
    "blob_client = azureblob.BlockBlobService(\n",
    "    account_name=config._STORAGE_ACCOUNT_NAME,\n",
    "    account_key=config._STORAGE_ACCOUNT_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the blob client to create the containers in Azure Storage if they\n",
    "    # don't yet exist.\n",
    "\n",
    "input_container_name = 'input'\n",
    "blob_client.create_container(input_container_name, fail_on_exist=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file_paths = [os.path.join(sys.path[0], 'sleep.py'),\n",
    "                    os.path.join(sys.path[0], 'taskdata1.txt'),\n",
    "                    os.path.join(sys.path[0], 'taskdata2.txt'),\n",
    "                    os.path.join(sys.path[0],'commands.bat')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading file /home/fission/Desktop/Azure_batch/Practice/sleep.py to container [input]...\n",
      "Uploading file /home/fission/Desktop/Azure_batch/Practice/taskdata1.txt to container [input]...\n",
      "Uploading file /home/fission/Desktop/Azure_batch/Practice/taskdata2.txt to container [input]...\n",
      "Uploading file /home/fission/Desktop/Azure_batch/Practice/commands.bat to container [input]...\n"
     ]
    }
   ],
   "source": [
    "# Upload the data files.\n",
    "input_files = [\n",
    "    upload_file_to_container(blob_client, input_container_name, file_path)\n",
    "    for file_path in input_file_paths]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = batch_client.pool.enable_auto_scale(pool_id=config._POOL_ID,auto_scale_formula=formula,\n",
    "                                           auto_scale_evaluation_interval=timedelta(minutes=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<azure.batch.models._models_py3.TaskAddCollectionResult at 0x7fa3940f0070>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tasks = list()\n",
    "\n",
    "for idx, input_file in enumerate(input_files):\n",
    "    command = \"/bin/bash -c \\\"python {}\\\"\".format(input_file.file_path)\n",
    "    tasks.append(batch.models.TaskAddParameter(\n",
    "        id='Task{}'.format(idx),\n",
    "        command_line=command,\n",
    "        resource_files=[input_file]\n",
    "    ))\n",
    "batch_client.task.add_collection(config._JOB_ID, tasks) #Adding tasks to the Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Retrieving informating for each task\n",
    "task_id = []\n",
    "boolean = []\n",
    "for i in range(len(tasks)):\n",
    "    id_ = list(batch_client.task.list(job_id=config._JOB_ID))[i].as_dict()\n",
    "    boolean.append(False)\n",
    "    task_id.append(id_['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[False, False, False, False]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boolean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-08-10 01:01:20\n",
      "elapsed time : 0:08:54\n"
     ]
    }
   ],
   "source": [
    "# We may need to need check the status of pool autoscale before going to the next line. Until the Nodes\n",
    "# are allocated, we cant go check the status of Task\n",
    "starttime = datetime.now().replace(microsecond=0)\n",
    "print(starttime)\n",
    "while True:\n",
    "    pool_stat = batch_client.pool.get(pool_id=config._POOL_ID)\n",
    "    pool_stat = pool_stat.as_dict()\n",
    "    if pool_stat['current_low_priority_nodes'] > 0:\n",
    "#         time.sleep(30)    # Node is not ready\n",
    "        break\n",
    "print(f'elapsed time : {datetime.now().replace(microsecond=0)-starttime}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...\n",
      "Monitoring all tasks for 'Completed' state, timeout in 0:30:00......\n",
      "Monitoring all tasks for 'Completed' state, timeout in 0:30:00......\n",
      "Monitoring all tasks for 'Completed' state, timeout in 0:30:00......\n",
      "Monitoring all tasks for 'Completed' state, timeout in 0:30:00......\n",
      "Monitoring all tasks for 'Completed' state, timeout in 0:30:00......\n",
      "Monitoring all tasks for 'Completed' state, timeout in 0:30:00......\n",
      "Monitoring all tasks for 'Completed' state, timeout in 0:30:00......\n",
      "Monitoring all tasks for 'Completed' state, timeout in 0:30:00......\n",
      "Monitoring all tasks for 'Completed' state, timeout in 0:30:00......\n",
      "Monitoring all tasks for 'Completed' state, timeout in 0:30:00......\n",
      "Monitoring all tasks for 'Completed' state, timeout in 0:30:00......\n",
      "Monitoring all tasks for 'Completed' state, timeout in 0:30:00......\n",
      "Monitoring all tasks for 'Completed' state, timeout in 0:30:00......\n",
      "Monitoring all tasks for 'Completed' state, timeout in 0:30:00......\n",
      "Monitoring all tasks for 'Completed' state, timeout in 0:30:00......\n",
      "Monitoring all tasks for 'Completed' state, timeout in 0:30:00......\n",
      "Monitoring all tasks for 'Completed' state, timeout in 0:30:00......\n",
      "Monitoring all tasks for 'Completed' state, timeout in 0:30:00......\n",
      "Monitoring all tasks for 'Completed' state, timeout in 0:30:00......\n",
      "Monitoring all tasks for 'Completed' state, timeout in 0:30:00......\n",
      "Monitoring all tasks for 'Completed' state, timeout in 0:30:00......\n",
      "Monitoring all tasks for 'Completed' state, timeout in 0:30:00......\n",
      "Monitoring all tasks for 'Completed' state, timeout in 0:30:00......\n",
      "Monitoring all tasks for 'Completed' state, timeout in 0:30:00......\n",
      "Monitoring all tasks for 'Completed' state, timeout in 0:30:00......\n",
      "Monitoring all tasks for 'Completed' state, timeout in 0:30:00......\n",
      "Monitoring all tasks for 'Completed' state, timeout in 0:30:00......\n",
      "Monitoring all tasks for 'Completed' state, timeout in 0:30:00......\n",
      "Monitoring all tasks for 'Completed' state, timeout in 0:30:00......\n",
      "Monitoring all tasks for 'Completed' state, timeout in 0:30:00......\n",
      "Monitoring all tasks for 'Completed' state, timeout in 0:30:00......\n",
      "Monitoring all tasks for 'Completed' state, timeout in 0:30:00......\n",
      "Monitoring all tasks for 'Completed' state, timeout in 0:30:00......\n",
      "Monitoring all tasks for 'Completed' state, timeout in 0:30:00......\n",
      "Monitoring all tasks for 'Completed' state, timeout in 0:30:00......\n",
      "Monitoring all tasks for 'Completed' state, timeout in 0:30:00......\n",
      "Monitoring all tasks for 'Completed' state, timeout in 0:30:00......\n",
      "Monitoring all tasks for 'Completed' state, timeout in 0:30:00......\n",
      "Monitoring all tasks for 'Completed' state, timeout in 0:30:00......\n",
      "Monitoring all tasks for 'Completed' state, timeout in 0:30:00......\n",
      "Monitoring all tasks for 'Completed' state, timeout in 0:30:00......\n",
      "Monitoring all tasks for 'Completed' state, timeout in 0:30:00......\n",
      "Monitoring all tasks for 'Completed' state, timeout in 0:30:00......\n",
      "Monitoring all tasks for 'Completed' state, timeout in 0:30:00......\n",
      "Monitoring all tasks for 'Completed' state, timeout in 0:30:00......\n",
      "Monitoring all tasks for 'Completed' state, timeout in 0:30:00......\n",
      "Monitoring all tasks for 'Completed' state, timeout in 0:30:00......\n",
      "Monitoring all tasks for 'Completed' state, timeout in 0:30:00......\n",
      "Monitoring all tasks for 'Completed' state, timeout in 0:30:00......\n",
      "Monitoring all tasks for 'Completed' state, timeout in 0:30:00......\n",
      "Monitoring all tasks for 'Completed' state, timeout in 0:30:00......\n",
      "Monitoring all tasks for 'Completed' state, timeout in 0:30:00......\n",
      "Monitoring all tasks for 'Completed' state, timeout in 0:30:00......\n",
      "Monitoring all tasks for 'Completed' state, timeout in 0:30:00......\n",
      "Monitoring all tasks for 'Completed' state, timeout in 0:30:00......\n",
      "Monitoring all tasks for 'Completed' state, timeout in 0:30:00......\n",
      "Monitoring all tasks for 'Completed' state, timeout in 0:30:00......\n",
      "Monitoring all tasks for 'Completed' state, timeout in 0:30:00......\n",
      "Monitoring all tasks for 'Completed' state, timeout in 0:30:00......\n",
      "Monitoring all tasks for 'Completed' state, timeout in 0:30:00......\n",
      "Monitoring all tasks for 'Completed' state, timeout in 0:30:00......\n",
      "Monitoring all tasks for 'Completed' state, timeout in 0:30:00......\n",
      "Monitoring all tasks for 'Completed' state, timeout in 0:30:00......\n",
      "Monitoring all tasks for 'Completed' state, timeout in 0:30:00......\n",
      "Monitoring all tasks for 'Completed' state, timeout in 0:30:00......\n",
      "Monitoring all tasks for 'Completed' state, timeout in 0:30:00......\n",
      "Monitoring all tasks for 'Completed' state, timeout in 0:30:00......\n",
      "Monitoring all tasks for 'Completed' state, timeout in 0:30:00......\n",
      "Monitoring all tasks for 'Completed' state, timeout in 0:30:00......\n",
      "Monitoring all tasks for 'Completed' state, timeout in 0:30:00......\n",
      "Node: tvmps_b4b16f9c509413e332eeb135ff2f939f6b4d8619533182610e7e42afdbdd81ad_p\n",
      "task id : Task2 is completed\n",
      "Task: Task2\n",
      "std_output : \n",
      "error_output :   File \"taskdata2.txt\", line 1\n",
      "    Azure Storage offers a set of storage services for all your business needs. Choose from Blob Storage (Object Storage) for unstructured data, File Storage for SMB-based cloud file shares, Table Storage for NoSQL data, Queue Storage to reliably store messages, and Premium Storage for high-performance, low-latency block storage for I/O-intensive workloads running in Azure Virtual Machines.\n",
      "                ^\n",
      "SyntaxError: invalid syntax\n",
      "\n",
      "...\n",
      "Node: tvmps_d6a63f7f4562b0f1d29c5635cc823f1c71de3b3bf0e941d8652908911f49fc3a_p\n",
      "task id : Task3 is completed\n",
      "Task: Task3\n",
      "std_output : \n",
      "error_output :   File \"commands.bat\", line 1\n",
      "    apt update\n",
      "             ^\n",
      "SyntaxError: invalid syntax\n",
      "\n",
      "...\n",
      "Monitoring all tasks for 'Completed' state, timeout in 0:30:00......\n",
      "Node: tvmps_b4b16f9c509413e332eeb135ff2f939f6b4d8619533182610e7e42afdbdd81ad_p\n",
      "task id : Task1 is completed\n",
      "Task: Task1\n",
      "std_output : \n",
      "error_output :   File \"taskdata1.txt\", line 1\n",
      "    Batch processing began with mainframe computers and punch cards. Today it still plays a central role in business, engineering, science, and other pursuits that require running lots of automated tasks—processing bills and payroll, calculating portfolio risk, designing new products, rendering animated films, testing software, searching for energy, predicting the weather, and finding new cures for disease. Previously only a few had access to the computing power for these scenarios. With Azure Batch, that power is available to you when you need it, without any capital investment.\n",
      "                   ^\n",
      "SyntaxError: invalid syntax\n",
      "\n",
      "Running another cycle in 30 secs\n",
      "Running another cycle in 30 secs\n",
      "...\n",
      "Monitoring all tasks for 'Completed' state, timeout in 0:30:00...Running another cycle in 30 secs\n",
      "Running another cycle in 30 secs\n",
      "Running another cycle in 30 secs\n",
      "...\n",
      "Node: tvmps_d6a63f7f4562b0f1d29c5635cc823f1c71de3b3bf0e941d8652908911f49fc3a_p\n",
      "task id : Task0 is completed\n",
      "Task: Task0\n",
      "std_output : \n",
      "error_output : \n",
      "elapsed time : 0:16:36\n"
     ]
    }
   ],
   "source": [
    "iscompleted = False\n",
    "while True:\n",
    "    iscompleted = True\n",
    "    try:\n",
    "        for i in range(len(task_id)):\n",
    "            if boolean[i]==False:\n",
    "                status_client = batch_client.task.get(job_id=config._JOB_ID,task_id=task_id[i])\n",
    "                status = status_client.as_dict()\n",
    "                print('...')\n",
    "                print(\"Monitoring all tasks for 'Completed' state, timeout in {}...\"\n",
    "                          .format(timedelta(minutes=30)), end='')\n",
    "                \n",
    "                if status['state'] != 'completed':    # Checking the status of task for completion\n",
    "#                     print(\"task id : {} is {}\".format(task_id[i],status['state'])) \n",
    "                    iscompleted = False\n",
    "                else:\n",
    "                    node_id = batch_client.task.get(job_id=config._JOB_ID,task_id=task_id[i]).node_info.node_id\n",
    "                    print(\"Node: {}\".format(node_id))\n",
    "                    print(\"task id : {} is {}\".format(task_id[i],status['state']))\n",
    "                    print(\"Task: {}\".format(task_id[i]))\n",
    "                    std_stream = batch_client.file.get_from_task(job_id=config._JOB_ID,task_id=task_id[i],\n",
    "                                                                 file_path=config._STANDARD_OUT_FILE_NAME)\n",
    "                    err_stream = batch_client.file.get_from_task(job_id=config._JOB_ID,task_id=task_id[i],\n",
    "                                                                     file_path=config._STANDARD_ERROR_OUT_FILE_NAME)\n",
    "                    \n",
    "                    std_file_text = _read_stream_as_string(std_stream,None)\n",
    "                    print(f'std_output : {std_file_text}')\n",
    "                    \n",
    "                    std_err_file_text = _read_stream_as_string(err_stream,None) \n",
    "                    print(f'error_output : {std_err_file_text}')\n",
    "                    \n",
    "                    boolean[i]=True\n",
    "            elif iscompleted != True:\n",
    "                print(\"Running another cycle in 30 secs\")\n",
    "                time.sleep(30)\n",
    "    except batchmodels.BatchErrorException as err:\n",
    "        print_batch_exception(err)\n",
    "        raise\n",
    "    if iscompleted:\n",
    "        break\n",
    "print(f'elapsed time : {datetime.now().replace(microsecond=0)-starttime}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "tvmps_d6a63f7f4562b0f1d29c5635cc823f1c71de3b3bf0e941d8652908911f49fc3a_p\n",
      "1\n",
      "tvmps_b4b16f9c509413e332eeb135ff2f939f6b4d8619533182610e7e42afdbdd81ad_p\n",
      "2\n",
      "tvmps_b4b16f9c509413e332eeb135ff2f939f6b4d8619533182610e7e42afdbdd81ad_p\n",
      "3\n",
      "tvmps_d6a63f7f4562b0f1d29c5635cc823f1c71de3b3bf0e941d8652908911f49fc3a_p\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(task_id)):\n",
    "    print(i)\n",
    "    node_id = batch_client.task.get(job_id=config._JOB_ID,task_id=task_id[i]).node_info.node_id\n",
    "    print(node_id)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[True, True]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boolean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# task1 gets completed in 10 sec\n",
    "# task2 is in pending\n",
    "# task3 complete\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_count = batch_client.job.get_task_counts(job_id=config._JOB_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'active': 0, 'running': 0, 'completed': 4, 'succeeded': 1, 'failed': 3}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task_count.as_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deleting the tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in task_id:\n",
    "    batch_client.task.delete(job_id=config._JOB_ID,task_id=i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# error = batchmodels.TaskFailureInformation(category='SyntaxError') # Syntax error is not valid error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batchmodels.TaskConstraints() # Need to work on this. This is useful for timeout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(boolean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_client.task.add()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchmodels.OnAllTasksComplete()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
