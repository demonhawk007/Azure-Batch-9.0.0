{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import uuid\n",
    "import sys\n",
    "import time\n",
    "import config\n",
    "from datetime import datetime, timedelta\n",
    "import azure.storage.blob as azureblob\n",
    "import azure.batch.models as batchmodels\n",
    "import azure.batch._batch_service_client as batch\n",
    "import azure.batch.batch_auth as batch_auth\n",
    "import azure.batch.operations as batchops\n",
    "from azure.batch.models import (VirtualMachineConfiguration, CloudServiceConfiguration, ImageReference,\n",
    "                                BatchErrorException, PoolInformation, JobAddParameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_batch_exception(batch_exception):\n",
    "    \"\"\"\n",
    "    Prints the contents of the specified Batch exception.\n",
    "\n",
    "    :param batch_exception:\n",
    "    \"\"\"\n",
    "    print('-------------------------------------------')\n",
    "    print('Exception encountered:')\n",
    "    if batch_exception.error and \\\n",
    "            batch_exception.error.message and \\\n",
    "            batch_exception.error.message.value:\n",
    "        print(batch_exception.error.message.value)\n",
    "        if batch_exception.error.values:\n",
    "            print()\n",
    "            for mesg in batch_exception.error.values:\n",
    "                print('{}:\\t{}'.format(mesg.key, mesg.value))\n",
    "    print('-------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_file_to_container(block_blob_client, container_name, file_path):\n",
    "    \"\"\"\n",
    "    Uploads a local file to an Azure Blob storage container.\n",
    "\n",
    "    :param block_blob_client: A blob service client.\n",
    "    :type block_blob_client: `azure.storage.blob.BlockBlobService`\n",
    "    :param str container_name: The name of the Azure Blob storage container.\n",
    "    :param str file_path: The local path to the file.\n",
    "    :rtype: `azure.batch.models.ResourceFile`\n",
    "    :return: A ResourceFile initialized with a SAS URL appropriate for Batch\n",
    "    tasks.\n",
    "    \"\"\"\n",
    "    blob_name = os.path.basename(file_path)\n",
    "\n",
    "    print('Uploading file {} to container [{}]...'.format(file_path,\n",
    "                                                          container_name))\n",
    "\n",
    "    block_blob_client.create_blob_from_path(container_name,\n",
    "                                            blob_name,\n",
    "                                            file_path)\n",
    "\n",
    "    sas_token = block_blob_client.generate_blob_shared_access_signature(\n",
    "        container_name,\n",
    "        blob_name,\n",
    "        permission=azureblob.BlobPermissions.READ,\n",
    "        expiry=datetime.utcnow() + timedelta(hours=2))\n",
    "\n",
    "    sas_url = block_blob_client.make_blob_url(container_name,\n",
    "                                              blob_name,\n",
    "                                              sas_token=sas_token)\n",
    "\n",
    "    return batchmodels.ResourceFile(http_url=sas_url, file_path=blob_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_container_sas_token(block_blob_client,\n",
    "                            container_name, blob_permissions):\n",
    "    \"\"\"\n",
    "    Obtains a shared access signature granting the specified permissions to the\n",
    "    container.\n",
    "\n",
    "    :param block_blob_client: A blob service client.\n",
    "    :type block_blob_client: `azure.storage.blob.BlockBlobService`\n",
    "    :param str container_name: The name of the Azure Blob storage container.\n",
    "    :param BlobPermissions blob_permissions:\n",
    "    :rtype: str\n",
    "    :return: A SAS token granting the specified permissions to the container.\n",
    "    \"\"\"\n",
    "    # Obtain the SAS token for the container, setting the expiry time and\n",
    "    # permissions. In this case, no start time is specified, so the shared\n",
    "    # access signature becomes valid immediately.\n",
    "    container_sas_token = \\\n",
    "        block_blob_client.generate_container_shared_access_signature(\n",
    "            container_name,\n",
    "            permission=blob_permissions,\n",
    "            expiry=datetime.utcnow() + timedelta(hours=2))\n",
    "\n",
    "    return container_sas_token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Batch Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "credentials = batch_auth.SharedKeyCredentials(account_name=config._BATCH_ACCOUNT_NAME,key=config._BATCH_ACCOUNT_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_client = batch.BatchServiceClient(credentials=credentials, batch_url=config._BATCH_ACCOUNT_URL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate an autoscale formula for the Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "formula = '''startingNumberOfVMs = 0;\n",
    "maxNumberofVMs = 10;\n",
    "pendingTaskSamplePercent = $PendingTasks.GetSamplePercent(180 * TimeInterval_Second);\n",
    "pendingTaskSamples = pendingTaskSamplePercent < 70 ? startingNumberOfVMs : avg($PendingTasks.GetSample(180 * TimeInterval_Second));\n",
    "$TargetLowPriorityNodes=min(maxNumberofVMs, pendingTaskSamples);\n",
    "$NodeDeallocationOption = taskcompletion;'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pool_eval = batch_client.pool.evaluate_auto_scale(pool_id=config._POOL_ID,auto_scale_formula=formula) # To work upon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pool_eval = pool_eval.as_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting to list\n",
    "# pp = pool_eval['results'].replace('$','').replace('=',\";\").split(';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting to Dictionary\n",
    "# pool_stat = dict(zip(pp[::2],pp[1::2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Need to have a check here as well that pendingTaskSamples must be 0 only then we can go ahead\n",
    "while True:\n",
    "    pool_eval = batch_client.pool.evaluate_auto_scale(pool_id=config._POOL_ID,auto_scale_formula=formula) # To work upon\n",
    "    pool_eval = pool_eval.as_dict()\n",
    "    pp = pool_eval['results'].replace('$','').replace('=',\";\").split(';')\n",
    "    pool_stat = dict(zip(pp[::2],pp[1::2]))\n",
    "    if pool_stat['pendingTaskSamples']=='0':\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a Container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the blob client, for use in obtaining references to\n",
    "    # blob storage containers and uploading files to containers.\n",
    "\n",
    "blob_client = azureblob.BlockBlobService(\n",
    "    account_name=config._STORAGE_ACCOUNT_NAME,\n",
    "    account_key=config._STORAGE_ACCOUNT_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the blob client to create the containers in Azure Storage if they\n",
    "    # don't yet exist.\n",
    "\n",
    "input_container_name = 'input'\n",
    "blob_client.create_container(input_container_name, fail_on_exist=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file_paths = [os.path.join(sys.path[0], 'sleep.py'),\n",
    "#                     os.path.join(sys.path[0], 'taskdata1.txt'),\n",
    "#                     os.path.join(sys.path[0], 'taskdata2.txt'),\n",
    "                    os.path.join(sys.path[0],'commands.bat')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading file /home/fission/Desktop/Azure_batch/Practice/sleep.py to container [input]...\n",
      "Uploading file /home/fission/Desktop/Azure_batch/Practice/commands.bat to container [input]...\n"
     ]
    }
   ],
   "source": [
    "# Upload the data files.\n",
    "input_files = [\n",
    "    upload_file_to_container(blob_client, input_container_name, file_path)\n",
    "    for file_path in input_file_paths]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = batch_client.pool.enable_auto_scale(pool_id=config._POOL_ID,auto_scale_formula=formula,\n",
    "                                           auto_scale_evaluation_interval=timedelta(minutes=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<azure.batch.models._models_py3.TaskAddCollectionResult at 0x7f29002216d0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tasks = list()\n",
    "\n",
    "for idx, input_file in enumerate(input_files):\n",
    "    command = \"/bin/bash -c \\\"bash {}\\\"\".format(input_file.file_path)\n",
    "    tasks.append(batch.models.TaskAddParameter(\n",
    "        id='Task{}'.format(idx),\n",
    "        command_line=command,\n",
    "        resource_files=[input_file]\n",
    "    ))\n",
    "batch_client.task.add_collection(config._JOB_ID, tasks) #Adding tasks to the Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Retrieving informating for each task\n",
    "task_id = []\n",
    "boolean = []\n",
    "for i in range(len(tasks)):\n",
    "    id_ = list(batch_client.task.list(job_id=config._JOB_ID))[i].as_dict()\n",
    "    boolean.append(False)\n",
    "    task_id.append(id_['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[False, False]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boolean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed time : 0:07:28\n"
     ]
    }
   ],
   "source": [
    "# We may need to need check the status of pool autoscale before going to the next line. Until the Nodes\n",
    "# are allocated, we cant go check the status of Task\n",
    "starttime = datetime.now().replace(microsecond=0)\n",
    "while True:\n",
    "    pool_stat = batch_client.pool.get(pool_id=config._POOL_ID)\n",
    "    pool_stat = pool_stat.as_dict()\n",
    "    if pool_stat['current_low_priority_nodes'] > 0:\n",
    "        break\n",
    "print(f'elapsed time : {datetime.now().replace(microsecond=0)-starttime}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...\n",
      "task id : Task0 still active\n",
      "...\n",
      "task id : Task1 still active\n",
      "...\n",
      "task id : Task0 is completed\n",
      "...\n",
      "task id : Task1 is completed\n"
     ]
    }
   ],
   "source": [
    "iscompleted = False\n",
    "while True:\n",
    "    iscompleted = True\n",
    "    try:\n",
    "        for i in range(len(task_id)):\n",
    "            if boolean[i]==False:\n",
    "                y = batch_client.task.get(job_id=config._JOB_ID,task_id=task_id[i])\n",
    "                y = y.as_dict()\n",
    "                print('...')\n",
    "                if y['state'] != 'completed':    # Checking the status of task for completion\n",
    "                    print(\"task id : {} still {}\".format(task_id[i],y['state']))\n",
    "                    iscompleted = False\n",
    "                else:\n",
    "                    print(\"task id : {} is {}\".format(task_id[i],y['state']))\n",
    "                    boolean[i]=True\n",
    "        if iscompleted != True:\n",
    "            time.sleep(30)\n",
    "    except batchmodels.BatchErrorException as err:\n",
    "        print_batch_exception(err)\n",
    "        raise\n",
    "    if iscompleted:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[True, True]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boolean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# task1 gets completed in 10 sec\n",
    "# task2 is in pending\n",
    "# task3 complete\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_count = batch_client.job.get_task_counts(job_id=config._JOB_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'active': 0, 'running': 0, 'completed': 2, 'succeeded': 0, 'failed': 2}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task_count.as_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deleting the tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in task_id:\n",
    "    batch_client.task.delete(job_id=config._JOB_ID,task_id=i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
